from fastapi import APIRouter, Body, HTTPException, status
from pydantic import BaseModel, constr
from typing import List, Optional
import logging
from python_worker.main import query_local_llm

router = APIRouter()

MAX_TEXT_LENGTH = 100_000  # Same as review step

class GenerateTutorQuestionsRequest(BaseModel):
    reviewed_text: constr(min_length=1, max_length=MAX_TEXT_LENGTH)
    filename: Optional[str] = None
    filetype: Optional[str] = None

class TutorQuestion(BaseModel):
    type: str = "open"  # "open" or "mcq"
    question: str  # For open questions, the question text; for MCQs, the stem
    answer: str
    reference: Optional[str] = None  # Can reference slides, sections, images, tables, etc
    difficulty: str                  # Now mandatory
    hint: Optional[str] = None
    tags: List[str]                  # New: required tags
    # MCQ-specific fields
    options: Optional[List[str]] = None  # For MCQs only
    explanation: Optional[str] = None    # For MCQs only

class GenerateTutorQuestionsResponse(BaseModel):
    success: bool
    questions: List[TutorQuestion]
    learning_objectives: List[str] = []  # Add learning objectives to response
    message: Optional[str] = None

def parse_llm_questions(llm_output) -> tuple[List[TutorQuestion], List[str]]:
    questions = []
    learning_objectives = llm_output.get("learning_objectives", [])
    
    for item in llm_output.get("tutor_questions", []):
        difficulty = item.get("difficulty")
        tags = item.get("tags", [])
        if not difficulty or not tags:
            continue  # Skip incomplete questions
            
        question_type = item.get("type", "open")
        
        if question_type == "open":
            questions.append(
                TutorQuestion(
                    type="open",
                    question=item.get("question", ""),
                    answer=item.get("answer", ""),
                    reference=item.get("reference"),
                    difficulty=difficulty,
                    hint=item.get("hint"),
                    tags=tags,
                )
            )
        elif question_type == "mcq":
            stem = item.get("stem", "") or item.get("question", "")  # Handle both stem and question fields
            options = item.get("options", [])
            answer = item.get("answer", "")
            explanation = item.get("explanation", "")
            ref = item.get("reference")
            hint = item.get("hint")
            mcq_tags = item.get("tags", [])
            
            questions.append(
                TutorQuestion(
                    type="mcq",
                    question=stem,  # Use stem for MCQ questions
                    answer=answer,
                    reference=ref,
                    difficulty=difficulty,
                    hint=hint,
                    tags=mcq_tags,
                    options=options,
                    explanation=explanation,
                )
            )
    return questions, learning_objectives

@router.post("/generate-tutor-questions", response_model=GenerateTutorQuestionsResponse, status_code=status.HTTP_200_OK)
async def generate_tutor_questions(request: GenerateTutorQuestionsRequest = Body(...)):
    text = request.reviewed_text.strip()
    if not text:
        raise HTTPException(status_code=422, detail="Reviewed text is empty.")
    if len(text) > MAX_TEXT_LENGTH:
        raise HTTPException(status_code=413, detail=f"Text too long. Max allowed is {MAX_TEXT_LENGTH} characters.")

    try:
        llm_output = query_local_llm(text)
        questions, learning_objectives = parse_llm_questions(llm_output)
    except Exception as e:
        logging.error(f"Error during LLM question generation: {e}")
        raise HTTPException(status_code=500, detail=f"Error during question generation: {str(e)}")

    if not questions:
        raise HTTPException(status_code=204, detail="No tutor questions were generated by the AI.")

    return GenerateTutorQuestionsResponse(
        success=True,
        questions=questions,
        learning_objectives=learning_objectives,
        message="Tutor questions generated successfully."
    )

# Create alias for production endpoint
@router.post("/tutor-questions", response_model=GenerateTutorQuestionsResponse, status_code=status.HTTP_200_OK)
async def tutor_questions(request: GenerateTutorQuestionsRequest = Body(...)):
    """Production endpoint for tutor questions - same as /generate-tutor-questions"""
    return await generate_tutor_questions(request)